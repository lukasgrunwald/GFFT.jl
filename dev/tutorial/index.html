<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Theory · GFFT.jl</title><meta name="title" content="Theory · GFFT.jl"/><meta property="og:title" content="Theory · GFFT.jl"/><meta property="twitter:title" content="Theory · GFFT.jl"/><meta name="description" content="Documentation for GFFT.jl."/><meta property="og:description" content="Documentation for GFFT.jl."/><meta property="twitter:description" content="Documentation for GFFT.jl."/><meta property="og:url" content="https://lukasgrunwald.github.io/GFFT.jl/tutorial/"/><meta property="twitter:url" content="https://lukasgrunwald.github.io/GFFT.jl/tutorial/"/><link rel="canonical" href="https://lukasgrunwald.github.io/GFFT.jl/tutorial/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">GFFT.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Theory</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#The-DFT-Algorithm"><span>The DFT Algorithm</span></a></li><li class="toplevel"><a class="tocitem" href="#Quadratures-for-Strongly-Oscillatory-Integrals"><span>Quadratures for Strongly Oscillatory Integrals</span></a></li><li class="toplevel"><a class="tocitem" href="#Numerical-Fourier-Transforms"><span>Numerical Fourier Transforms</span></a></li></ul></li><li><a class="tocitem" href="../library/">Library</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Theory</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Theory</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/lukasgrunwald/GFFT.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/lukasgrunwald/GFFT.jl/blob/master/docs/src/tutorial.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Theoretical-Background"><a class="docs-heading-anchor" href="#Theoretical-Background">Theoretical Background</a><a id="Theoretical-Background-1"></a><a class="docs-heading-anchor-permalink" href="#Theoretical-Background" title="Permalink"></a></h1><p>This is part of an appendix of my master thesis in theoretical condensed matter physics, that explains the basic algorithm, and it&#39;s application to approximate continuous Fourier transforms. For an alternative and more complete description see the Fourier transform chapter of <a href="http://numerical.recipes/">Numerical Recipies</a>.</p><h1 id="The-DFT-Algorithm"><a class="docs-heading-anchor" href="#The-DFT-Algorithm">The DFT Algorithm</a><a id="The-DFT-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#The-DFT-Algorithm" title="Permalink"></a></h1><p>The DFT (and IDFT) maps a sequence <span>$\{s[n] \mid n \in [ 0, 1, \dots N-1] \}$</span> onto a new sequence <span>$\{\hat{s}[k] \mid k \in [0, 1, \dots N-1] \}$</span> by implementing the sums</p><p class="math-container">\[\begin{align}
    \text{ DFT:} \quad \hat{s}[k] &amp;= \sum_{n=0}^{N-1} e^{-i\frac{2\pi}{N} n \cdot k} \; s[n], \\
    \text{IDFT:} \quad s[n] &amp;= \frac{1}{N}\sum_{n=0}^{N-1} e^{+i\frac{2\pi}{N} n \cdot k} \; \hat{s}[k].
\end{align}\]</p><p>Because of the Euler identity <span>$e^{2\pi i k} = 1 \; \forall k \in \mathbb{Z}$</span>, a DFT always acts on the periodically continued signal, i.e. it is implied that <span>$\hat{s}[k+N]=\hat{s}[k]$</span> and in turn <span>$s[n+N]=s[n]$</span>, which can be seen by inspection of (1) and (2). The Euler identity also leads to the Nyquist theorem: The &quot;frequencies&quot; <span>$k \in [N/2, \dots ,N-1]$</span> are the same as <span>$k \in [-N/2, \dots, -1]$</span>, meaning that the DFT does not actually calculate frequencies with <span>$k \geq N/2$</span>, but rather, it always generates an (asymmetric) frequency-array around the origin, i.e. <span>$k \in [0, \dots, N/2-1, -N/2, \dots, -1]$</span>. An array in this ordering is called FFT-ordered. This array can be ordered in <span>$\mathcal{O}(N)$</span> by using a circular index shift (circshift).</p><p>A naive implementation of the DFT has <span>$\mathcal{O}(N^2)$</span> complexity, but with a clever trick which was popularized by the <a href="https://en.wikipedia.org/wiki/Cooley%E2%80%93Tukey_FFT_algorithm">Cooley-Tukey FFT algorithm</a>, this can be improved to <span>$\mathcal{O}(N \log(N))$</span> if <span>$N = 2^m, \; m \in \mathbb{N}$</span>. (Generalizations are possible to the case where <span>$N$</span> is a product of low prime numbers, but these are extremely complicated.) The main insight comes from splitting of the DFT (or IDFT) into even and odd terms</p><p class="math-container">\[\begin{align}
    \hat{s}[k] &amp;= \sum_{n=0}^{N/2-1} e^{-i\frac{2\pi}{N/2} n \cdot k} \; s[2n] +
    e^{-i\frac{2\pi}{N}k}\sum_{n=0}^{N/2-1} e^{-i\frac{2\pi}{N/2} n \cdot k} \; s[2n+1] \\
    &amp;= x_{even}[k] + e^{-i\frac{2\pi}{N}k} x_{odd}[k],
\end{align}\]</p><p>followed by the realization that <span>$x_{odd}$</span> and <span>$x_{even}$</span> are again DFT&#39;s with length <span>$N/2$</span> that can be calculated recursively. The recursion depth being <span>$x=\log_2(N)$</span>, <span>$\hat{s}[k]$</span> can be calculated in <span>$\mathcal{O}\big( N^2/2^x + xN \big) \in \mathcal{O}(N \log(N))$</span>, where the first term describes the recursion and the second term the recombination step.</p><p>Next to this basic idea, a plethora of tricks (cache locality, SIMD-instruction etc.) are used in modern DFT implementations leading to further <span>$\mathcal{O}(N)$</span>-speedups. This is why in this thesis we use the Julia bindings to the <a href="https://www.fftw.org/">FFTW (&quot;Fastest Fourier Transform in the West&quot;)</a> library for calculating DFT&#39;s, instead of relying on a custom version.</p><h1 id="Quadratures-for-Strongly-Oscillatory-Integrals"><a class="docs-heading-anchor" href="#Quadratures-for-Strongly-Oscillatory-Integrals">Quadratures for Strongly Oscillatory Integrals</a><a id="Quadratures-for-Strongly-Oscillatory-Integrals-1"></a><a class="docs-heading-anchor-permalink" href="#Quadratures-for-Strongly-Oscillatory-Integrals" title="Permalink"></a></h1><p>As a proxy for the continuous FT, we next discuss how to numerically calculate strongly oscillatory integrals for f: \mathbb{R} \to \mathbb{C}, f \in L^2 $ of the form</p><p class="math-container">\[\begin{equation}
    \hat{f}(\omega) = \int_a^b \text{d} t \;  e^{i\omega t} f(t),
\end{equation}\]</p><p>where we are usually interested in many values of <span>$\omega$</span>. A naive, but illustrative approach is to choose a uniform discretization of the time axis <span>$t=a + j\Delta, j\in[0, N]$</span> with spacing <span>$\Delta = N^{-1}(b-a)$</span> and function values <span>$f_j \equiv f(t_j)$</span>, and to evaluate the integral using the trapezoidal-rule (or more generally Gregory Integration).<sup class="footnote-reference"><a id="citeref-1" href="#footnote-1">[1]</a></sup></p><p>The sum in the resulting expression</p><p class="math-container">\[\begin{equation}
    \hat{f}(\omega) \approx \Delta e^{i\omega a} \sum_{n=0}^{N-1} f_j e^{i\omega \Delta j}
    - \frac{\Delta}{2} \Big( e^{i\omega a}h_0 - e^{i\omega b}h_N \Big)
\end{equation}\]</p><p>can be efficiently calculated using the DFT, when choosing <span>$\omega_j = 2\pi (b-a)^{-1}  [-\frac{N}{2}, \dots, \frac{N}{2}-1]_j$</span>. As noted before, the frequency array resulting from a DFT is asymmetric around the origin, <span>$\omega_{-N/2}$</span> being the smallest and <span>$\omega_{N/2-1}$</span> the largest value. To generate a symmetric array, which is usually needed for further calculations, we obtain <span>$\omega_{N/2}$</span> using a third-order spline extrapolation, using the last three frequency points. In cases where the data is &quot;noisy&quot;, i.e. where we have residual fluctuations from the DFT we sometimes also use the previous frequency point as an approximation for <span>$\omega_{N/2}$</span>.</p><p>Notice that the grid-spacing is <span>$\delta \omega \sim (b-a)^{-1}$</span> and <span>$\omega\_{max} \sim N$</span>, meaning that while the latter is determined by our discretization, the first is fixed by the integral itself. It is possible to decrease <span>$\delta \omega$</span> by using zero-padding, but this only corresponds to a sinc-interpolation of the original <span>$\hat{f}(\omega)$</span> and thus does not contain new information, so that the frequency resolution in this approach is fundamentally limited by <span>$\delta \omega = 2\pi (b-a)^{-1}$</span>. <sup class="footnote-reference"><a id="citeref-2" href="#footnote-2">[2]</a></sup> Nonetheless, zero-padding is very useful, as it represents a cheap way to obtain a high order interpolation of <span>$\hat{f}(\omega)$</span> which is e.g. needed when <span>$\hat{f}(\omega)$</span> is to be used in further analysis.</p><p>While (6) can give accurate results if <span>$\lim_{t \to a,b} f(t) \approx 0$</span> fast enough (e.g. exponentially fast), in general it will be vastly inaccurate. The issue is that due to the oscillatory nature of the integral, the small parameter appearing in error terms is not <span>$\Delta / (b-a)$</span>, but rather <span>$\omega \Delta$</span>, which can become as large as <span>$\pi$</span>. As a result (6) becomes systematically inaccurate as <span>$\omega$</span> increases.</p><p>A more sophisticated approach can be formulated by approximating <span>$f(t)$</span> by its polynomial interpolation of order <span>$s$</span> with mesh-points <span>$f_j \equiv f(t_j)$</span>, with <span>$t_j$</span> as defined above. This can be viewed as approximating <span>$f(t)$</span> by a sum of kernel functions which only depend on the interpolation scheme used</p><p class="math-container">\[\begin{equation}
    f(t) \approx
     \sum_{j=0}^N f_j \psi \bigg(\frac{t-t_j}{\Delta} \bigg) 
    + \sum_{j \in \text{endpts}} f_j \phi_j \bigg(\frac{t-t_j}{\Delta}\bigg).
\end{equation}\]</p><p>Here <span>$\psi(s)$</span> are the kernel function of an interior point (Lagrange-polynomials of order <span>$s$</span>) and <span>$\phi_j(s)$</span> are the boundary corrections, which are needed since close to <span>$a,b$</span> non-centered interpolation formulas have to be used. The number of endpoint functions is equal to <span>$2s$</span>: <span>$s$</span> functions at every side of the interval. Inserting (7) into (5) and exchanging sum and integral, one can rewrite the expression as</p><p class="math-container">\[\begin{equation}
    \hat{f}(\omega_n) = \Delta e^{i\omega_n a} W(\theta_n) 
    \sum_{j=0}^{N-1} f_j e^{i\theta_n j}
    + \Delta \sum_{k=0}^{s-1} \Big( f_k \alpha_k(\theta_n) e^{i\omega_n a} 
    + f_{N-k} \tilde{\alpha}_{k}(\theta_n) e^{i\omega_n b} \Big).
\end{equation}\]</p><p>Here we introduced the shorthand <span>$\theta_n = \omega_n \Delta$</span>, with <span>$\omega_n$</span> defined such that the DFT can be used for the first sum.<sup class="footnote-reference"><a id="citeref-3" href="#footnote-3">[3]</a></sup> Further, we defined the two functions (the <span>$\tilde{\alpha}_k$</span>&#39;s can be expressed in terms of <span>$\alpha_k$</span>&#39;s, see below)</p><p class="math-container">\[\begin{align}
    W(\theta) = \int_{-\infty}^\infty \text{d} s \; e^{is\theta} \psi(s), \qquad
    \alpha_j(\theta) = \int_{-\infty}^{\infty} \text{d} s \; e^{i\theta} \phi_j(s-j).
\end{align}\]</p><p>For the cubic (<span>$s=3$</span>) interpolation scheme, the explicit expressions for <span>$W, \alpha, \tilde{\alpha}$</span> read</p><p class="math-container">\[\begin{align}
    W(\theta) &amp;= \left(\frac{6 + \theta^2}{3\theta^4}\right)
    \left[ 3 - 4 \cos\theta + \cos 2 \theta \right] \\
    \alpha_0(\theta) &amp;= 
    \frac{(-42 + 5 \theta^2) (6 \theta^2) (8 \cos \theta - \cos 2\theta)}{6\theta^4}
    + i \frac{(-12\theta + 6\theta^3) + (6 + \theta^2) \sin 2\theta}{6\theta^4}, \\
    \alpha_1(\theta) &amp;= \frac{14(3 - \theta^2)- 7(6 + \theta^2) \cos \theta}{6\theta^4} + 
    \frac{30\theta - 5(6 + \theta^2) \sin \theta}{6\theta^4}, \\
    \alpha_2(\theta) &amp;= \frac{-4(3 - \theta^2) + 2(6 + \theta^2) \cos \theta}{3\theta^4} + 
    i \frac{-12\theta + 2(6 + \theta^2) \sin \theta}{3\theta^4}, \\
    \alpha_3(\theta) &amp;= \frac{2(3 - \theta^2) - (6 + \theta^2) \cos \theta}{6 \theta^4} +
    i \frac{6\theta - (6 + \theta^2) \sin \theta}{6 \theta^4}, \\
    \tilde{\alpha}_{0}(\theta) &amp;= \frac{(-6 + 11\theta^2) + (6 \theta^2)\cos 2\theta}{6\theta^4} - i \Im[\alpha_0(\theta)], \\
    \tilde{\alpha}_{k \geq 1}(\theta) &amp;= \alpha_{k}^*(\theta) .
\end{align}\]</p><p>These formulas have cancelations to high orders in <span>$\theta$</span>, such that in a numerical implementation their 6th order Taylor-expansion has to be used for <span>$|\theta| &lt; 0.11$</span>, instead of the full expression. The <em>crossover-value</em> of <span>$\theta$</span> is determined experimentally as the value when Taylor expansion and analytical expression give the same result and dependents on details of the programming language and implementation (see <code>benchmark/optimization_eps.jl</code>). Note that the asymptotic complexity of (8) is the same as for the naive trapezoidal rule approach (6), i.e. <span>$\mathcal{O}(N \log N)$</span>.</p><h1 id="Numerical-Fourier-Transforms"><a class="docs-heading-anchor" href="#Numerical-Fourier-Transforms">Numerical Fourier Transforms</a><a id="Numerical-Fourier-Transforms-1"></a><a class="docs-heading-anchor-permalink" href="#Numerical-Fourier-Transforms" title="Permalink"></a></h1><p>Calculating continuous FT&#39;s, which are integrals of type (5) with <span>$b=-a=\infty$</span>, viz.</p><p class="math-container">\[\begin{align}
    f(t) = \int_{-\infty}^\infty \frac{d\omega}{2 \pi} \; e^{-i \omega t} \hat{f}(\omega), \qquad
    \hat{f}(\omega) = \int_{-\infty}^\infty dt \; e^{i \omega t} f(t),
\end{align}\]</p><p>is in general very difficult. If the function falls off reasonably quickly at infinity (We found that a decay as <span>$\mathcal{O}(t^{-2},\omega^{-2})$</span> is usually fast enough.), we can split the integration interval at some <span>$s_{max}$</span> and neglect the boundary terms <span>$\sim \int_{s_{max}}^{\infty} \dots$</span>, leaving us with an integral that can be performed using (8). The resulting frequency array has the form <span>$\omega_j = \frac{\pi}{s_{max}} [-N/2, \dots, N/2]_j$</span>, so that <span>$\omega_{max} \sim N/s_{max}$</span> and <span>$\delta \omega \sim s\_{max}^{-1}$</span>. Both parameters can be controlled by our discretization and cutoff. In general, the convergence in <span>$N, s_{max}$</span> has to be checked on a case-by-case basis.</p><p>If the function is not decaying fast enough, as is the case for the free retarted Greens function <span>$G^R(\omega) \stackrel{\omega \to \infty}{\sim} (\omega + i0^+)^{-1} \equiv G_{asy.}^R(\omega)$</span> we can still use above formalism, given that the asymptotic behavior is known and that the FT of the asymptotic expression (here the FT of <span>$G_{asy.}^R(\omega)$</span>) can be worked out analytically. If this is the case, we numerically calculate the FT of <span>$(G^R - G^R\_{asy.})(\omega)$</span> and add the analytically obtained $ \hat{G}^R_{asy.}(t)$ to the result</p><p class="math-container">\[\begin{equation}
    G^R(t) \approx \int_{-s_{max}}^{s_{max}} \frac{d\omega}{2 \pi} e^{-i \omega t} 
    \underbrace{\big(G^R - G_{asy.}^R\big)(\omega)}_{\in \mathcal{O}(\omega^{-2})}
    + G\_{asy.}\^R(t).
\end{equation}\]</p><p>In a numerical setting <span>$0^+$</span> in <span>$G_{asy.}^R(\omega)$</span> is replaced by a finite broadening factor <span>$0^+ \to \eta=0.1$</span>, leading to the analytical result <span>$G_{asy.}^R(t) = -i\Theta(t) e^{-\eta t}$</span>.</p><p>In addition to continuous FT&#39;s appearing in the real time formalisms, we are also working in imaginary time, where the corresponding Matsubara Fourier Transforms (MFT) are defined as </p><p class="math-container">\[\begin{align}
    f(\tau) = \frac{1}{\beta} \sum_{\omega_n} e^{-i\omega_n\tau} \hat{f}(i\omega_n),  \qquad
    \hat{f}(i\omega_n) = \int_0^\beta d\tau \; e^{i\omega_n\tau} f(\tau),
\end{align}\]</p><p>with inverse temperature <span>$\beta=\frac{1}{T}$</span> and Matsubara frequencies <span>$\omega_n = 2\pi \beta^{-1} \left( \mathbb{Z} + \zeta/2 \right)_n$</span>. We have <span>$\zeta = 1$</span> for fermions and <span>$\zeta = 0$</span> for bosons. Discretizing imaginary time as <span>$\tau_j = \Delta [0, \dots, N]_j$</span> with <span>$\Delta = \beta / N$</span>, the transform <span>$f(\tau) \to \hat{f}(i \omega_n)$</span> can be calculated using (7) as</p><p class="math-container">\[\begin{equation}
    \hat{f}(i\omega_n) =
    \int_0^\beta d\tau \; e^{i \frac{2\pi}{\beta} n \tau} \big[ e^{\zeta \frac{i\pi}{\beta} \tau}  f(\tau) \big],
\end{equation}\]</p><p>where the additional phase factor appears because of the definition of Matsubara frequencies.</p><p>The transform <span>$\hat{f}(i \omega_n) \to f(\tau)$</span> is again more tricky because of the infinite boundaries. If the function decays fast enough we can split the Matsubara sum at <span>$\omega_{max} \sim N_{max}$</span> and neglect the boundary term <span>$\sim \sum_{N_{max+1}}^\infty \dots$</span>, leaving us with a sum that can be calculated using the DFT, after an appropriate circshift. The resulting <span>$\tau$</span>-array of the DFT has the form <span>$\tilde{\tau}_j = \frac{\beta}{N}[-N/2, \dots, N/2]_j$</span>, but because of the periodicity <span>$f(\tau + \beta) = (-1)^{\zeta} f(\tau)$</span>, this is equivalent to <span>$\tau \in [0, \beta]$</span>. Explicitly, we thus implement</p><p class="math-container">\[\begin{equation}
    f(\tau_j) 
    \approx \frac{1}{\beta} e^{-\zeta \frac{i\pi}{\beta} \tau_j} \sum_{ |n| \leq N_{max}} 
    e^{-i\frac{2\pi}{\beta} n \tau_j} \hat{f}(i\omega_n).
\end{equation}\]</p><p>If the <span>$\hat{f}(i \omega)$</span> is not decaying fast enough, we again use the trick of subtracting and adding the asymptotic contribution. Such a slow decay is seen for <span>$G(i \omega_n) \stackrel{n \to \infty}{\sim}(i \omega_n)^{-1} \equiv G\_{asy.}(i \omega)$</span>, where the analytically calculated transform of the asymptotic reads <span>$G_{asy.}(\tau) = -1/2$</span> for <span>$\tau \in [0, \beta]$</span>.</p><p>In practice, we often successively apply FT&#39;s to the same set of functions in an iterative loop. In this case one can eliminate the need of doing a circshift after each iteration, if the integration interval is symmetric around the origin. In this case, applying the DFT to the ordered <span>$f$</span>-array followed by multiplication of <span>$e^{i\omega_n a}$</span> [see (7)] is equivalent to just applying the DFT to the <em>FFT-ordered</em> array.</p><section class="footnotes is-size-7"><ul><li class="footnote" id="footnote-1"><a class="tag is-link" href="#citeref-1">1</a>Since we want to evaluate the integral at many values of <span>$\omega$</span> and because we often only know <span>$f(t)$</span> at fixed, evenly spaced points, standard high-order rules such as Gauss-quadratures are infeasible since they scale as <span>$\mathcal{O}(N^2)$</span> and often even require interpolation. They would not be significantly more accurate than the trapezoidal rule anyway, as we will shortly explain.</li><li class="footnote" id="footnote-2"><a class="tag is-link" href="#citeref-2">2</a>This is not an issue for us, since the values of <span>$a,b$</span> will usually also be numerical parameters (see below).</li><li class="footnote" id="footnote-3"><a class="tag is-link" href="#citeref-3">3</a>Remarks concerning the <span>$\omega$</span>-grid, made in the context of the naive approach, of course also apply here.</li></ul></section></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../library/">Library »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 10 June 2024 11:04">Monday 10 June 2024</span>. Using Julia version 1.7.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
